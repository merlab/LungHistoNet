{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TILES = \"Tiles\"\n",
    "PATH_TO_COORDS = \"Coordinates\"\n",
    "GENERATED_DIR = \"Generated\"\n",
    "IMAGE_SIZE_W = 256\n",
    "IMAGE_SIZE_L = 256\n",
    "\n",
    "os.makedirs(GENERATED_DIR, exist_ok=True)\n",
    "\n",
    "for subfolder in os.listdir(PATH_TO_COORDS):\n",
    "    coords_subfolder_path = os.path.join(PATH_TO_COORDS, subfolder)\n",
    "    tiles_subfolder_path = os.path.join(PATH_TO_TILES, subfolder)\n",
    "    generated_subfolder_path = os.path.join(GENERATED_DIR, subfolder)\n",
    "\n",
    "    if not os.path.exists(tiles_subfolder_path):\n",
    "        continue\n",
    "\n",
    "    os.makedirs(generated_subfolder_path, exist_ok=True)\n",
    "\n",
    "    for coord_file in os.listdir(coords_subfolder_path):\n",
    "        if coord_file.endswith(\"_coords.txt\"):\n",
    "            base_name = coord_file[:-11]\n",
    "\n",
    "            coord_file_path = os.path.join(coords_subfolder_path, coord_file)\n",
    "            tile_image_path = os.path.join(tiles_subfolder_path, base_name + \".png\")\n",
    "\n",
    "            if not os.path.exists(tile_image_path):\n",
    "                continue\n",
    "\n",
    "            with open(coord_file_path, 'r') as file:\n",
    "                line_count = file.read().count('\\n')\n",
    "\n",
    "            label = \"low\" if line_count < 5 else \"high\"\n",
    "\n",
    "            with Image.open(tile_image_path) as img:\n",
    "                resized_img = img.resize((IMAGE_SIZE_W, IMAGE_SIZE_L))\n",
    "                output_file_name = f\"{base_name}_{label}.png\"\n",
    "                output_file_path = os.path.join(generated_subfolder_path, output_file_name)\n",
    "                resized_img.save(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = np.empty((0, 256, 256, 3), dtype=np.float32) \n",
    "labels = np.empty((0,), dtype=np.int32)\n",
    "\n",
    "def label_to_numeric(label):\n",
    "    return 0 if label == \"low\" else 1  # Map \"low\" to 0 and \"high\" to 1\n",
    "\n",
    "for subfolder in os.listdir(GENERATED_DIR):\n",
    "    subfolder_path = os.path.join(GENERATED_DIR, subfolder)\n",
    "\n",
    "    if os.path.isdir(subfolder_path): \n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "            file_path = os.path.join(subfolder_path, file_name)\n",
    "\n",
    "            if file_name.endswith(\".png\"):\n",
    "                label = file_name.split(\"_\")[-1].split(\".\")[0]  # Get \"low\" or \"high\"\n",
    "\n",
    "                with Image.open(file_path) as img:\n",
    "                    if img.mode == \"RGBA\":\n",
    "                        img = img.convert(\"RGB\")\n",
    "\n",
    "                    img_array = np.array(img) / 255.0  \n",
    "\n",
    "                    if img_array.shape != (256, 256, 3):\n",
    "                        print(f\"Skipping image due to unexpected shape: {img_array.shape}\")\n",
    "                        continue\n",
    "\n",
    "                    image_data = np.vstack([image_data, img_array[np.newaxis, ...]])\n",
    "                    labels = np.append(labels, label_to_numeric(label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GeneratedDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.images[idx], dtype=torch.float32).permute(2, 0, 1)  \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "dataset = GeneratedDataset(image_data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for batch_images, batch_labels in dataloader:\n",
    "    print(batch_images.shape, batch_labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_data, labels))\n",
    "\n",
    "dataset = dataset.shuffle(len(image_data)).batch(32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
