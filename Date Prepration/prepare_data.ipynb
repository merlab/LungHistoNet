{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:57:14.303643: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-05 14:57:14.450474: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ProcessPoolExecutor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Classifiaction (Low,High)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TILES = \"Tiles\"\n",
    "PATH_TO_COORDS = \"Coordinates\"\n",
    "GENERATED_DIR = \"Generated\"\n",
    "IMAGE_SIZE_W = 256\n",
    "IMAGE_SIZE_L = 256\n",
    "\n",
    "os.makedirs(GENERATED_DIR, exist_ok=True)\n",
    "\n",
    "for subfolder in os.listdir(PATH_TO_COORDS):\n",
    "    coords_subfolder_path = os.path.join(PATH_TO_COORDS, subfolder)\n",
    "    tiles_subfolder_path = os.path.join(PATH_TO_TILES, subfolder)\n",
    "    generated_subfolder_path = os.path.join(GENERATED_DIR, subfolder)\n",
    "\n",
    "    if not os.path.exists(tiles_subfolder_path):\n",
    "        continue\n",
    "\n",
    "    os.makedirs(generated_subfolder_path, exist_ok=True)\n",
    "\n",
    "    for coord_file in os.listdir(coords_subfolder_path):\n",
    "        if coord_file.endswith(\"_coords.txt\"):\n",
    "            base_name = coord_file[:-11]\n",
    "\n",
    "            coord_file_path = os.path.join(coords_subfolder_path, coord_file)\n",
    "            tile_image_path = os.path.join(tiles_subfolder_path, base_name + \".png\")\n",
    "\n",
    "            if not os.path.exists(tile_image_path):\n",
    "                continue\n",
    "\n",
    "            with open(coord_file_path, 'r') as file:\n",
    "                line_count = file.read().count('\\n')\n",
    "\n",
    "            label = \"low\" if line_count < 5 else \"high\"\n",
    "\n",
    "            with Image.open(tile_image_path) as img:\n",
    "                resized_img = img.resize((IMAGE_SIZE_W, IMAGE_SIZE_L))\n",
    "                output_file_name = f\"{base_name}_{label}.png\"\n",
    "                output_file_path = os.path.join(generated_subfolder_path, output_file_name)\n",
    "                resized_img.save(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Regression (Msaked based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_65480_54972_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_45836_121142_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_60569_122160_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_42562_119106_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_27829_47846_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_19644_40720_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_27829_57008_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_27829_50900_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_65480_58026_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_55658_124196_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_22918_43774_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_63843_55990_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_19644_45810_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_67117_40720_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_45836_120124_coords.txt because it is empty.\n",
      "Skipping /home/gandalf/Documents/Code/Lung_Injury/Coordinates/Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_3/tile_70391_54972_coords.txt because it is empty.\n",
      "Skipping Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_6 because no corresponding coordinates folder exists.\n",
      "Skipping Observer-2 (Prarthna)/ALI_surgical_w_catheter_m_5 because no corresponding coordinates folder exists.\n",
      "Skipping Observer-3 (Kasuni)/ALI_surgical_w_catheter_m_4 because no corresponding coordinates folder exists.\n",
      "Skipping Observer-3 (Kasuni)/ALI_Study4_Jun_2022_Mouse_3 because no corresponding coordinates folder exists.\n",
      "Skipping Observer-3 (Kasuni)/ALI_surgical_w_catheter_m_1 because no corresponding coordinates folder exists.\n",
      "Skipping Observer-1 (Eva)/ALI_Study4_Jun_2022_Mouse_8 because no corresponding coordinates folder exists.\n",
      "Skipping Observer-1 (Eva)/ALI_surgical_w_catheter_m_7 because no corresponding coordinates folder exists.\n",
      "Skipping Observer-1 (Eva)/ALI_surgical_w_catheter_m_2 because no corresponding coordinates folder exists.\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_TILES = os.path.expanduser('~/Documents/Code/Lung_Injury/Tiles/')\n",
    "PATH_TO_COORDS = os.path.expanduser('~/Documents/Code/Lung_Injury/Coordinates/')\n",
    "GENERATED_DIR = os.path.expanduser('~/Documents/Code/Lung_Injury/Generated_Masks')\n",
    "RESIZED_TILES_DIR = os.path.expanduser('~/Documents/Code/Lung_Injury/Resized_Tiles')\n",
    "\n",
    "IMAGE_SIZE_W = 512\n",
    "IMAGE_SIZE_L = 512\n",
    "\n",
    "os.makedirs(GENERATED_DIR, exist_ok=True)\n",
    "os.makedirs(RESIZED_TILES_DIR, exist_ok=True)\n",
    "\n",
    "def process_file(coord_file_path, tile_image_path, resized_subfolder_path, generated_subfolder_path):\n",
    "    if os.path.getsize(coord_file_path) == 0:\n",
    "        print(f\"Skipping {coord_file_path} because it is empty.\")\n",
    "        return\n",
    "    \n",
    "    base_name = os.path.basename(coord_file_path)[:-11]\n",
    "    with Image.open(tile_image_path) as img:\n",
    "        orig_w, orig_h = img.size\n",
    "        mask = np.zeros((orig_h, orig_w), dtype=np.uint8)\n",
    "        with open(coord_file_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            line_count = len(lines)\n",
    "            for line in lines:\n",
    "                coords = line.strip().split(\",\")\n",
    "                if len(coords) >= 4:\n",
    "                    x1, y1, x2, y2 = map(int, coords[:4])\n",
    "                    mask[y1:y2, x1:x2] = 255\n",
    "        mask_resized = Image.fromarray(mask).resize((IMAGE_SIZE_W, IMAGE_SIZE_L), Image.NEAREST)\n",
    "        img_resized = img.resize((IMAGE_SIZE_W, IMAGE_SIZE_L))\n",
    "        resized_tile_path = os.path.join(resized_subfolder_path, f\"{base_name}_{line_count}.png\")\n",
    "        img_resized.save(resized_tile_path)\n",
    "        output_file_path = os.path.join(generated_subfolder_path, f\"{base_name}_mask_{line_count}.png\")\n",
    "        mask_resized.save(output_file_path)\n",
    "\n",
    "def process_subfolder(subfolder):\n",
    "    coords_subfolder_path = os.path.join(PATH_TO_COORDS, subfolder)\n",
    "    tiles_subfolder_path = os.path.join(PATH_TO_TILES, subfolder)\n",
    "    generated_subfolder_path = os.path.join(GENERATED_DIR, subfolder)\n",
    "    resized_subfolder_path = os.path.join(RESIZED_TILES_DIR, subfolder)\n",
    "    \n",
    "    if not os.path.exists(coords_subfolder_path):\n",
    "        print(f\"Skipping {subfolder} because no corresponding coordinates folder exists.\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(tiles_subfolder_path):\n",
    "        print(f\"Skipping {subfolder} because no corresponding tiles folder exists.\")\n",
    "        return\n",
    "    \n",
    "    os.makedirs(generated_subfolder_path, exist_ok=True)\n",
    "    os.makedirs(resized_subfolder_path, exist_ok=True)\n",
    "    \n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for coord_file in os.listdir(coords_subfolder_path):\n",
    "            if coord_file.endswith(\"_coords.txt\"):\n",
    "                coord_file_path = os.path.join(coords_subfolder_path, coord_file)\n",
    "                base_name = coord_file[:-11]\n",
    "                tile_image_path = os.path.join(tiles_subfolder_path, base_name + \".png\")\n",
    "                if not os.path.exists(tile_image_path):\n",
    "                    print(f\"Skipping {tile_image_path} because the corresponding tile image does not exist.\")\n",
    "                    continue\n",
    "                futures.append(executor.submit(process_file, coord_file_path, tile_image_path, resized_subfolder_path, generated_subfolder_path))\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "\n",
    "for observer_folder in os.listdir(PATH_TO_TILES):\n",
    "    observer_path = os.path.join(PATH_TO_TILES, observer_folder)\n",
    "    if os.path.isdir(observer_path):\n",
    "        for subfolder in os.listdir(observer_path):\n",
    "            subfolder_path = os.path.join(observer_path, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                process_subfolder(os.path.join(observer_folder, subfolder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Classifiaction (Low,High)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = np.empty((0, 256, 256, 3), dtype=np.float32) \n",
    "labels = np.empty((0,), dtype=np.int32)\n",
    "\n",
    "def label_to_numeric(label):\n",
    "    return 0 if label == \"low\" else 1  # Map \"low\" to 0 and \"high\" to 1\n",
    "\n",
    "for subfolder in os.listdir(GENERATED_DIR):\n",
    "    subfolder_path = os.path.join(GENERATED_DIR, subfolder)\n",
    "\n",
    "    if os.path.isdir(subfolder_path): \n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "            file_path = os.path.join(subfolder_path, file_name)\n",
    "\n",
    "            if file_name.endswith(\".png\"):\n",
    "                label = file_name.split(\"_\")[-1].split(\".\")[0]  # Get \"low\" or \"high\"\n",
    "\n",
    "                with Image.open(file_path) as img:\n",
    "                    if img.mode == \"RGBA\":\n",
    "                        img = img.convert(\"RGB\")\n",
    "\n",
    "                    img_array = np.array(img) / 255.0  \n",
    "\n",
    "                    if img_array.shape != (256, 256, 3):\n",
    "                        print(f\"Skipping image due to unexpected shape: {img_array.shape}\")\n",
    "                        continue\n",
    "\n",
    "                    image_data = np.vstack([image_data, img_array[np.newaxis, ...]])\n",
    "                    labels = np.append(labels, label_to_numeric(label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_data, labels))\n",
    "\n",
    "dataset = dataset.shuffle(len(image_data)).batch(32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Regression (Msaked based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image directory exists: True\n",
      "Mask directory exists: True\n",
      "Number of images: 5\n",
      "Number of masks: 5\n",
      "\n",
      "First 5 image paths:\n",
      "Resized_Tiles/tile_29466_120124_29.png\n",
      "Resized_Tiles/tile_29466_121142_11.png\n",
      "Resized_Tiles/tile_31103_115034_21.png\n",
      "Resized_Tiles/tile_31103_116052_12.png\n",
      "Resized_Tiles/tile_31103_117070_12.png\n",
      "\n",
      "First 5 mask paths:\n",
      "Generated_Masks/tile_29466_120124_mask_29.png\n",
      "Generated_Masks/tile_29466_121142_mask_11.png\n",
      "Generated_Masks/tile_31103_115034_mask_21.png\n",
      "Generated_Masks/tile_31103_116052_mask_12.png\n",
      "Generated_Masks/tile_31103_117070_mask_12.png\n",
      "\n",
      "Shapes of loaded data:\n",
      "Images shape: (5, 512, 512, 3)\n",
      "Masks shape: (5, 512, 512, 1)\n",
      "Counts shape: (5,)\n",
      "\n",
      "Batch shapes:\n",
      "Images shape: (5, 512, 512, 3)\n",
      "Masks shape: (5, 512, 512, 1)\n",
      "Counts: [29. 11. 21. 12. 12.]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def load_image(image_path):\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")  \n",
    "    image = np.array(image) / 255.0 \n",
    "    return image\n",
    "\n",
    "def load_mask(mask_path):\n",
    "\n",
    "    mask = Image.open(mask_path).convert(\"L\") \n",
    "    mask = np.array(mask) / 255.0 \n",
    "    mask = np.expand_dims(mask, axis=-1) \n",
    "    return mask\n",
    "\n",
    "def parse_filename(filename):\n",
    "\n",
    "    base_name = os.path.basename(filename)\n",
    "    count = int(base_name.split(\"_\")[-1].split(\".\")[0]) \n",
    "    return count\n",
    "\n",
    "def create_dataset(image_dir, mask_dir):\n",
    "\n",
    "    image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(\".png\")])\n",
    "    mask_paths = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith(\".png\")])\n",
    "\n",
    "    print(f\"Number of images: {len(image_paths)}\")\n",
    "    print(f\"Number of masks: {len(mask_paths)}\")\n",
    "\n",
    "    if len(image_paths) != len(mask_paths):\n",
    "        raise ValueError(f\"Mismatch between number of images ({len(image_paths)}) and masks ({len(mask_paths)})\")\n",
    "\n",
    "    print(\"\\nFirst 5 image paths:\")\n",
    "    for path in image_paths[:5]:\n",
    "        print(path)\n",
    "    print(\"\\nFirst 5 mask paths:\")\n",
    "    for path in mask_paths[:5]:\n",
    "        print(path)\n",
    "\n",
    "    images = np.array([load_image(img_path) for img_path in image_paths])\n",
    "    masks = np.array([load_mask(mask_path) for mask_path in mask_paths])\n",
    "    counts = np.array([parse_filename(f) for f in image_paths], dtype=np.float32)\n",
    "\n",
    "    print(\"\\nShapes of loaded data:\")\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Masks shape: {masks.shape}\")\n",
    "    print(f\"Counts shape: {counts.shape}\")\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, masks, counts))\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "image_dir = \"Resized_Tiles\"\n",
    "mask_dir = \"Generated_Masks\"\n",
    "\n",
    "print(f\"Image directory exists: {os.path.exists(image_dir)}\")\n",
    "print(f\"Mask directory exists: {os.path.exists(mask_dir)}\")\n",
    "\n",
    "dataset = create_dataset(image_dir, mask_dir)\n",
    "\n",
    "for images, masks, counts in dataset.take(1):\n",
    "    print(\"\\nBatch shapes:\")\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Masks shape:\", masks.shape)\n",
    "    print(\"Counts:\", counts.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 18:07:51.258946: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT32 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 39s/step - loss: 316.6488 - regression_output_loss: 315.6646 - regression_output_mae: 16.3452 - segmentation_output_accuracy: 0.0897 - segmentation_output_loss: 0.9842 - val_loss: 249.3206 - val_regression_output_loss: 249.0643 - val_regression_output_mae: 14.1367 - val_segmentation_output_accuracy: 0.9918 - val_segmentation_output_loss: 0.2564\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 243.0906 - regression_output_loss: 242.8461 - regression_output_mae: 14.4730 - segmentation_output_accuracy: 0.9921 - segmentation_output_loss: 0.2446 - val_loss: 220.0009 - val_regression_output_loss: 219.8742 - val_regression_output_mae: 13.0648 - val_segmentation_output_accuracy: 0.9936 - val_segmentation_output_loss: 0.1267\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 187.7559 - regression_output_loss: 187.6633 - regression_output_mae: 12.9092 - segmentation_output_accuracy: 0.9936 - segmentation_output_loss: 0.0926 - val_loss: 193.6720 - val_regression_output_loss: 193.5787 - val_regression_output_mae: 12.0147 - val_segmentation_output_accuracy: 0.9939 - val_segmentation_output_loss: 0.0933\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 143.8590 - regression_output_loss: 143.7926 - regression_output_mae: 11.5437 - segmentation_output_accuracy: 0.9941 - segmentation_output_loss: 0.0665 - val_loss: 168.4387 - val_regression_output_loss: 168.3465 - val_regression_output_mae: 10.9102 - val_segmentation_output_accuracy: 0.9940 - val_segmentation_output_loss: 0.0922\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 109.9330 - regression_output_loss: 109.8578 - regression_output_mae: 10.2769 - segmentation_output_accuracy: 0.9941 - segmentation_output_loss: 0.0752 - val_loss: 142.4686 - val_regression_output_loss: 142.3650 - val_regression_output_mae: 9.6497 - val_segmentation_output_accuracy: 0.9940 - val_segmentation_output_loss: 0.1036\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 83.4149 - regression_output_loss: 83.3236 - regression_output_mae: 9.0311 - segmentation_output_accuracy: 0.9941 - segmentation_output_loss: 0.0914 - val_loss: 118.3801 - val_regression_output_loss: 118.2625 - val_regression_output_mae: 8.3275 - val_segmentation_output_accuracy: 0.9941 - val_segmentation_output_loss: 0.1176\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 63.1166 - regression_output_loss: 63.0110 - regression_output_mae: 7.8294 - segmentation_output_accuracy: 0.9941 - segmentation_output_loss: 0.1056 - val_loss: 97.1277 - val_regression_output_loss: 96.9993 - val_regression_output_mae: 6.9488 - val_segmentation_output_accuracy: 0.9941 - val_segmentation_output_loss: 0.1284\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 47.5575 - regression_output_loss: 47.4436 - regression_output_mae: 6.7248 - segmentation_output_accuracy: 0.9941 - segmentation_output_loss: 0.1139 - val_loss: 81.1916 - val_regression_output_loss: 81.0589 - val_regression_output_mae: 5.7744 - val_segmentation_output_accuracy: 0.9941 - val_segmentation_output_loss: 0.1327\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 35.8364 - regression_output_loss: 35.7213 - regression_output_mae: 5.7382 - segmentation_output_accuracy: 0.9941 - segmentation_output_loss: 0.1152 - val_loss: 70.8905 - val_regression_output_loss: 70.7607 - val_regression_output_mae: 5.3365 - val_segmentation_output_accuracy: 0.9941 - val_segmentation_output_loss: 0.1298\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 26.6044 - regression_output_loss: 26.4935 - regression_output_mae: 4.7998 - segmentation_output_accuracy: 0.9941 - segmentation_output_loss: 0.1110 - val_loss: 65.7178 - val_regression_output_loss: 65.5962 - val_regression_output_mae: 5.4529 - val_segmentation_output_accuracy: 0.9941 - val_segmentation_output_loss: 0.1217\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "IMAGE_SIZE = (512, 512)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def build_multi_task_model(input_shape=(512, 512, 3)):\n",
    "    \"\"\"\n",
    "    Build a multi-task model with a shared backbone and two heads:\n",
    "    - Segmentation head (mask prediction)\n",
    "    - Regression head (count prediction)\n",
    "    \"\"\"\n",
    "    # Shared backbone (e.g., ResNet50)\n",
    "    backbone = tf.keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        input_shape=input_shape,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "    backbone.trainable = True  # Fine-tune the backbone\n",
    "\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    features = backbone(inputs)\n",
    "\n",
    "    # Segmentation head\n",
    "    x = layers.Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(features)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # Upsample to 32x32\n",
    "    x = layers.Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # Upsample to 64x64\n",
    "    x = layers.Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # Upsample to 128x128\n",
    "    x = layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # Upsample to 256x256\n",
    "    x = layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # Upsample to 512x512\n",
    "    segmentation_output = layers.Conv2D(1, (1, 1), activation=\"sigmoid\", name=\"segmentation_output\")(x)\n",
    "\n",
    "    # Regression head\n",
    "    x = layers.GlobalAveragePooling2D()(features)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    regression_output = layers.Dense(1, name=\"regression_output\")(x)\n",
    "\n",
    "\n",
    "    model = tf.keras.Model(inputs, [segmentation_output, regression_output])\n",
    "    return model\n",
    "\n",
    "def prepare_dataset(dataset):\n",
    "\n",
    "    def map_fn(image, mask, count):\n",
    "        return image, (mask, count)\n",
    "    return dataset.map(map_fn)\n",
    "\n",
    "\n",
    "prepared_dataset = prepare_dataset(dataset)\n",
    "\n",
    "\n",
    "model = build_multi_task_model()\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss={\n",
    "        \"segmentation_output\": losses.binary_crossentropy,  # Loss for segmentation\n",
    "        \"regression_output\": losses.MSE  # Loss for regression\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"segmentation_output\": 1.0,  # Weight for segmentation loss\n",
    "        \"regression_output\": 1.0  # Weight for regression loss\n",
    "    },\n",
    "    metrics={\n",
    "        \"segmentation_output\": \"accuracy\",\n",
    "        \"regression_output\": \"mae\"\n",
    "    }\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    prepared_dataset,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(dataset) // BATCH_SIZE,\n",
    "    validation_data=prepared_dataset,\n",
    "    validation_steps=len(dataset) // BATCH_SIZE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
